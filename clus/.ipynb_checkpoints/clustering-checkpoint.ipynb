{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, LabelBinarizer, OneHotEncoder\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KElbowVisualizer\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmplot3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes3D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.impute import SimpleImputer \n",
    "import scipy.cluster.hierarchy as sch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\"/kaggle/input/customer-segmentation/customer_segmentation.csv\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info dari tabel\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info dari tabel\n",
    "dt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info missing dari tabel\n",
    "dt.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_box = ['Income']\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(col_box, 1):\n",
    "    plt.subplot((len(col_box) // 3) + 1, 3, i)\n",
    "    sns.histplot(data=dt, x=column, kde=True)\n",
    "    plt.xlabel(column)\n",
    "    plt.title(\"Histogram\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "cols = [\"Income\"]\n",
    "\n",
    "for col in cols:\n",
    "    dt[col] = num_imputer.fit_transform(dt[[col]]).squeeze()\n",
    "    dt[col] = dt[col].apply(np.floor)\n",
    "    \n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info missing dari tabel\n",
    "dt.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:01:22.737363Z",
     "iopub.status.busy": "2024-05-13T10:01:22.736956Z",
     "iopub.status.idle": "2024-05-13T10:01:22.742896Z",
     "shell.execute_reply": "2024-05-13T10:01:22.741453Z",
     "shell.execute_reply.started": "2024-05-13T10:01:22.737333Z"
    }
   },
   "source": [
    "# Mengelolah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"Dt_Customer\"] = pd.to_datetime(dt[\"Dt_Customer\"], format=\"%d-%m-%Y\")\n",
    "dates = []\n",
    "for i in dt[\"Dt_Customer\"]:\n",
    "    i = i.date()\n",
    "    dates.append(i)  \n",
    "\n",
    "print(\"Pelanggan baru:\",max(dates))\n",
    "print(\"Pelanggan lama:\",min(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = []\n",
    "d1 = max(dates) \n",
    "for i in dates:\n",
    "    delta = d1 - i\n",
    "    days.append(delta)\n",
    "dt[\"Customer_For\"] = days\n",
    "dt[\"Customer_For\"] = pd.to_numeric(dt[\"Customer_For\"], errors=\"coerce\")\n",
    "dt[\"Customer_For\"] = dt[\"Customer_For\"] / 100000000000\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Status pernikahan:\\n\", dt[\"Marital_Status\"].value_counts(), \"\\n\")\n",
    "print(\"Pendidikan:\\n\", dt[\"Education\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mendapatkan umur\n",
    "dt[\"Age\"] = 2024 - dt[\"Year_Birth\"]\n",
    "\n",
    "#pengeluaran\n",
    "dt[\"Spent\"] = dt[\"MntWines\"]+ dt[\"MntFruits\"]+ dt[\"MntMeatProducts\"]+ dt[\"MntFishProducts\"]+ dt[\"MntSweetProducts\"]+ dt[\"MntGoldProds\"]\n",
    "\n",
    "#status penikahan\n",
    "dt[\"Living_With\"] = dt[\"Marital_Status\"].replace({\"Together\":\"Married\", \"Absurd\":\"Alone\", \"Widow\":\"Alone\", \"Divorced\":\"Alone\", \"YOLO\":\"Alone\", \"Single\":\"Alone\",})\n",
    "\n",
    "#jumlah anak\n",
    "dt[\"Children\"] = dt[\"Kidhome\"] + dt[\"Teenhome\"]\n",
    "\n",
    "#pendidikan\n",
    "dt[\"Education\"] = dt[\"Education\"].replace({\"Basic\":\"Undergraduate\",\"2n Cycle\":\"Undergraduate\", \"Graduation\":\"Graduate\", \"Master\":\"Postgraduate\", \"PhD\":\"Postgraduate\"})\n",
    "\n",
    "#biar produknya lebih jelas\n",
    "dt = dt.rename(columns={\"MntWines\": \"Wines\",\"MntFruits\":\"Fruits\",\"MntMeatProducts\":\"Meat\",\"MntFishProducts\":\"Fish\",\"MntSweetProducts\":\"Sweets\",\"MntGoldProds\":\"Gold\"})\n",
    "\n",
    "#Drop beberapa data\n",
    "to_drop = [\"Marital_Status\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Year_Birth\", \"ID\"]\n",
    "dt = dt.drop(to_drop, axis=1)\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "def handle_encoding(dt, method, columns):\n",
    "    for column in columns:\n",
    "        dt[column] = method.fit_transform(dt[column])\n",
    "\n",
    "    return dt\n",
    "\n",
    "dt = handle_encoding(dt, le, [\"Education\"])\n",
    "dt = handle_encoding(dt, lb, [\"Living_With\"])\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_box = ['Income', 'Recency', 'Wines', 'Fruits', 'Meat', 'Fish',\n",
    "       'Sweets', 'Gold', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'Customer_For', 'Age', 'Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "for i, column in enumerate(col_box, 1):\n",
    "    plt.subplot((len(col_box)//3)+1, 3, i)\n",
    "    sns.boxplot(data=dt, x=column)    \n",
    "    plt.xlabel(column)\n",
    "    plt.title(f'{column} Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt[(dt[\"Age\"]<90)]\n",
    "dt = dt[(dt[\"Income\"]<140000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "for i, column in enumerate(col_box, 1):\n",
    "    plt.subplot((len(col_box)//3)+1, 3, i)\n",
    "    sns.boxplot(data=dt, x=column)    \n",
    "    plt.xlabel(column)\n",
    "    plt.title(f'{column} Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_box = ['Income', 'Recency', 'Wines', 'Fruits', 'Meat', 'Fish',\n",
    "       'Sweets', 'Gold', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'Customer_For', 'Age', 'Spent']\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(col_box, 1):\n",
    "    plt.subplot((len(col_box) // 3) + 1, 3, i)\n",
    "    sns.histplot(data=dt, x=column, kde=True)\n",
    "    plt.xlabel(column)\n",
    "    plt.title(f'{column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatbox = ['Education', 'Income', 'Recency', 'Wines', 'Fruits', 'Meat', 'Fish',\n",
    "       'Sweets', 'Gold', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
    "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
    "       'AcceptedCmp2', 'Complain', 'Response', 'Customer_For', 'Age', 'Spent',\n",
    "       'Living_With', 'Children']\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.heatmap(dt[heatbox].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "dT_pca = dt[heatbox].drop(columns = ['Recency', 'Education', 'Complain'])\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(dT_pca)\n",
    "pca_data = scaler.fit_transform(pca_data)\n",
    "pca_data = pd.DataFrame(pca_data, columns=[\"x\", 'y']) \n",
    "print(\"PCA explained variance ratio:\\n\", \" \".join(map(\"{:.3f}\".format, pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.scatter(pca_data[\"x\"], pca_data[\"y\"], s = 50)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Visualisasi PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = pca_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "scores = []\n",
    "for i in range(2, 10):\n",
    "    km = KMeans(n_clusters=i, init='k-means++', max_iter=500, n_init=10, random_state=42)\n",
    "    km.fit(pca_data)\n",
    "    wcss.append(km.inertia_)\n",
    "\n",
    "    labels = km.labels_\n",
    "    silhouette_avg = silhouette_score(pca_data, labels)\n",
    "    scores.append(silhouette_avg)\n",
    "    print('wcss score for n_cluster = ' + str(i) + ' is ' + str(wcss))\n",
    "    print('silhoutte score for n_clusters = ' + str(i) + ' is ' + str(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Silhouette Score\n",
    "plt.plot(range(2, 10), scores)\n",
    "plt.title('Silhouette Score', fontsize = 20)\n",
    "plt.xlabel('No. of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansmodel = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 42)\n",
    "y_kmeans= kmeansmodel.fit_predict(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "\n",
    "for i in range(len(kmeansmodel.cluster_centers_)):\n",
    "    plt.scatter(pca_data[y_kmeans == i, 0], pca_data[y_kmeans == i, 1], s=100, c=colors[i], label=f'Cluster {i+1}')\n",
    "\n",
    "plt.scatter(kmeansmodel.cluster_centers_[:, 0], kmeansmodel.cluster_centers_[:, 1], s=300, c='black', label='Centroids', marker='*')\n",
    "\n",
    "plt.title('Clustering Result K-Means PCA (After StandardScaler)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah sampel dalam setiap cluster\n",
    "cluster_counts = np.bincount(y_kmeans)\n",
    "\n",
    "# Membuat plot bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(len(cluster_counts)), cluster_counts, color=['red', 'blue', 'green', 'yellow'])\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Data Across Clusters')\n",
    "plt.xticks(np.arange(len(cluster_counts)), labels=np.arange(1, len(cluster_counts) + 1))  # Label sumbu x berdasarkan nomor cluster\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_col = 'ward'\n",
    "scores = []\n",
    "\n",
    "print('Linkage:', linkage_col)\n",
    "for i in range(2, 10):\n",
    "    AC = AgglomerativeClustering(n_clusters=i, linkage=linkage_col)\n",
    "    AC.fit(pca_data)\n",
    "    \n",
    "    labels = AC.labels_\n",
    "    silhouette_avg = silhouette_score(pca_data, labels)\n",
    "    scores.append(silhouette_avg)\n",
    "    print('Silhouette score for n_clusters =', i, 'is', silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"Set1\", 1) \n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(range(2, 10), scores, marker='o', color=colors[0], label=linkage_col)\n",
    "\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs. Number of Clusters for Agglomerative Clustering with Ward Method')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 4\n",
    "AC = AgglomerativeClustering(n_clusters=n_cluster, linkage='ward')\n",
    "labels = AC.fit_predict(pca_data)\n",
    "\n",
    "df_train_with_labels = np.column_stack((pca_data, labels))\n",
    "\n",
    "centroids = []\n",
    "for cluster_label in range(n_cluster):  \n",
    "    cluster_data = df_train_with_labels[df_train_with_labels[:, -1] == cluster_label]\n",
    "    cluster_centroid = np.mean(cluster_data[:, :-1], axis=0)\n",
    "    centroids.append(cluster_centroid)\n",
    "\n",
    "centroids = np.array(centroids)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "x = pca_data[:, 0]\n",
    "y = pca_data[:, 1]\n",
    "\n",
    "plt.scatter(x, y, c=labels, cmap='rainbow', label='Data Points')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='black', marker='*', s=100, label='Centroids')\n",
    "\n",
    "plt.title('Agglomerative Clustering Scatter Plot with Centroids')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = sch.linkage(pca_data, 'ward')\n",
    "plt.figure(figsize=(20,15))\n",
    "dendrogram = sch.dendrogram(linked, orientation='top',distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Distance')\n",
    "plt.axhline(y=10, color='black', linestyle='--') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4  # Jumlah klaster\n",
    "AC = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "labels = AC.fit_predict(pca_data)\n",
    "\n",
    "# Hitung jumlah sampel dalam setiap klaster\n",
    "cluster_counts = np.bincount(labels)\n",
    "\n",
    "# Buat plot bar chart dengan warna yang diatur berdasarkan colormap 'rainbow'\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(np.arange(len(cluster_counts)), cluster_counts, color=plt.cm.rainbow(np.linspace(0, 1, n_clusters)))\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Data Across Clusters')\n",
    "plt.xticks(np.arange(n_clusters), labels=np.arange(1, n_clusters + 1))  # Label sumbu x berdasarkan nomor klaster\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4]\n",
    "min_samples = [10, 15, 20, 25]\n",
    "\n",
    "sil_avg = []\n",
    "max_value = (0, 0, 0, -1)\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    for j in range(len(min_samples)):\n",
    "        db = DBSCAN(min_samples=min_samples[j], eps=epsilon[i]).fit(pca_data)\n",
    "\n",
    "        # cek jika lebih dari 2 cluster\n",
    "        unique_labels = set(db.labels_)\n",
    "        if len(unique_labels) >= 2:\n",
    "            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "            core_samples_mask[db.core_sample_indices_] = True\n",
    "            labels = db.labels_\n",
    "\n",
    "            # jumlah kluster\n",
    "            n_clusters_ = len(unique_labels) - (1 if -1 in labels else 0)\n",
    "            n_noise_ = list(labels).count(-1)\n",
    "\n",
    "            silhouette_avg = silhouette_score(pca_data, labels)\n",
    "            sil_avg.append(silhouette_avg)\n",
    "\n",
    "            if silhouette_avg > max_value[3]:\n",
    "                max_value = (epsilon[i], min_samples[j], n_clusters_, silhouette_avg)\n",
    "\n",
    "print(\"epsilon =\", max_value[0],\n",
    "      \"\\nmin_samples =\", max_value[1],\n",
    "      \"\\nnumber of clusters =\", max_value[2],\n",
    "      \"\\naverage silhouette score = %.4f\" % max_value[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persebaran data dari dimensi yang sudah dikurangi tidak membentuk gumpalan data, bisa terjadi mungkin karena cara mengelolah data yang masih belum benar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kesimpulan\n",
    "\n",
    "Menggunakan clustering k-means dan hierarchical menghasilkan 4 cluster dengan persebarannya masing-masing, dan untuk dbscan salah bisa terjadi karena data yang diolah masih belum sesuai"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4996698,
     "sourceId": 8398601,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
